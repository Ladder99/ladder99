# docker compose file for the complete ladder99 pipeline.
# can override these settings in a setup's docker-compose.yaml files.

# docker compose yaml version - must be a string
# see https://docs.docker.com/compose/compose-file/compose-file-v3
# note: a '3' here means '3.0'
version: '3.8'

services:
  # ---------------------------------------------------------------------------
  # adapter
  # ---------------------------------------------------------------------------
  # convert machine data to shdr and send to agent
  adapter:
    container_name: adapter

    # note: must specify build OR image in setup's compose-overrides.yaml.
    # build: ./services/adapter # see Dockerfile in this folder
    # image: ladder99/adapter:0.8.0-arm # an alternative to the build process

    # set this to give permission to access hardware (e.g. dymo scale in usb port).
    #. security hole - leave off for now, until need dymo driver - or do per setup.
    # privileged: true

    profiles:
      - adapter
    # use this to access kepware opcua on windows using host.docker.internal to reach localhost?
    #. is this actually needed?
    # extra_hosts:
    #   - "host.docker.internal:host-gateway"
    environment:
      # specify where code can find data.
      # can override at run time, eg to run service on windows with node.
      L99_SETUP_FOLDER: /data/setup
      L99_ADAPTER_FOLDER: /data/adapter
      # L99_DRIVER_FOLDER: /data/drivers
      L99_SCHEMA_FOLDER: /data/schemas
    volumes:
      - ./setups/$SETUP:/data/setup # has setup.yaml etc
      - ./setups/$SETUP/volumes/adapter:/data/adapter # has json cookies for backfilling
      # - ./setups/$SETUP/volumes/adapter/drivers:/data/drivers # has custom js drivers
      - ./setups/$SETUP/volumes/adapter/schemas:/data/schemas # has custom schema yamls
    restart: unless-stopped
    networks:
      - ladder99
    logging:
      options:
        max-size: '20m'

  # ---------------------------------------------------------------------------
  # agent
  # ---------------------------------------------------------------------------
  # take in shdr and output xml/json/html
  agent:
    container_name: agent
    #. use mtconnect/agent once mtconnect publishes theirs to docker hub
    # see https://hub.docker.com/repository/docker/ladder99/agent for ours
    image: ladder99/agent:1.7.0.3-0.1.2
    # image: ladder99/agent:2.0.0.11-arm
    profiles:
      - agent
    working_dir: /data/agent
    # note: agent will optionally print to stdout and/or dump to /data/agent/agent.log* files.
    # note: without this command, agent image runs a simulator of a cnc machine.
    command: agent run agent.cfg
    # command: agent debug agent.cfg
    volumes:
      - ./setups/$SETUP/volumes/agent:/data/agent # should have agent.cfg, agent.xml
    ports:
      - 5000:5000
    restart: unless-stopped
    networks:
      - ladder99
    logging:
      options:
        max-size: '20m'

  # ---------------------------------------------------------------------------
  # backup
  # ---------------------------------------------------------------------------
  # automatic/scheduled backup of database
  # see https://github.com/offen/docker-volume-backup
  backup:
    container_name: backup
    image: offen/docker-volume-backup:latest
    profiles:
      - backup
    restart: unless-stopped
    networks:
      - ladder99
    volumes:
      # By default a container based on this image will run in the UTC timezone. 
      # In case you want to run your cron rules in your local timezone (respecting DST), 
      # you can mount your Docker host's /etc/timezone and /etc/localtime:
      # (doesn't really matter, as servers are set to UTC anyway)
      - /etc/localtime:/etc/localtime:ro
      - /etc/timezone:/etc/timezone:ro
      #
      # without this backup doesn't communicate with other services properly (?)
      - /var/run/docker.sock:/var/run/docker.sock:ro
      #
      # By default, the `/backup` directory inside the container will be backed up.
      # In case you need to use a custom location, set `BACKUP_SOURCES`.
      - backup:/backup # a docker volume - see postgres service and end of this file
      #
      # If you mount a local directory or volume to `/archive`, a local
      # copy of the backup will be stored there.
      - ./setups/$SETUP/volumes/backup:/archive:rw
      #
      # NOTE: see postgres service labels for pre and post commands etc
      #
    environment:
      # NOTE: null values are set in .env - keep out of repo
      #
      # The name of the backup file including the `.tar.gz` extension.
      # IMPORTANT: override this in client's compose-overrides.yaml with client name!
      BACKUP_FILENAME: backup-CLIENT-%Y-%m-%dT%H-%M-%S.tar.gz
      BACKUP_PRUNING_PREFIX: backup-CLIENT-
      #
      # Setting BACKUP_FILENAME_EXPAND to true allows for environment variable
      # placeholders in BACKUP_FILENAME, BACKUP_LATEST_SYMLINK and in
      # BACKUP_PRUNING_PREFIX that will get expanded at runtime,
      # Please note that you will need to escape the `$` when providing the value
      # in a docker-compose.yml file, i.e. using $$VAR instead of $VAR.
      # note: the envar must be set BEFORE this compose yaml file is read. 
      # note: must be 'true', not true
      # BACKUP_FILENAME_EXPAND: 'true'
      #
      # pruning
      # In case your target bucket or directory contains other files than the ones
      # managed by this container, you can limit the scope of rotation by setting
      # a prefix value. This would usually be the non-parametrized part of your
      # BACKUP_FILENAME. E.g. if BACKUP_FILENAME is `db-backup-%Y-%m-%dT%H-%M-%S.tar.gz`,
      # you can set BACKUP_PRUNING_PREFIX to `db-backup-` and make sure
      # unrelated files are not affected by the rotation mechanism.
      # (ie it'll prune only file starting with this prefix)
      BACKUP_RETENTION_DAYS: 7
      BACKUP_CRON_EXPRESSION: '0 7 * * *' # 7am gmt ~ 1am cst
      #
      # cloud backup
      AWS_ENDPOINT: nyc3.digitaloceanspaces.com
      AWS_S3_BUCKET_NAME: ladder99
      AWS_ACCESS_KEY_ID: null
      AWS_SECRET_ACCESS_KEY: null
      # AWS_S3_PATH: backup/client # don't use this - causes probs with local backups
      #
      # slack notifications
      NOTIFICATION_URLS: null
      NOTIFICATION_LEVEL: info

    logging:
      options:
        max-size: '20m'

  # ---------------------------------------------------------------------------
  # cloudbeaver
  # ---------------------------------------------------------------------------
  # database web ui - more general than pgadmin
  cloudbeaver:
    container_name: cloudbeaver
    # need to use image OR build in client's compose-overrides.yaml.
    # (can't turn off a value with '' or null (?), so just commented both
    # image and build out).
    # see client-mazak for example of running cloudbeaver on x86.
    # see https://hub.docker.com/r/dbeaver/cloudbeaver/tags
    image: dbeaver/cloudbeaver:21.3.5 # use this for x86 etc
    # build: ./services/cloudbeaver # use this for ARM processors - need to build with Dockerfile
    profiles:
      - cloudbeaver
    volumes:
      # - ./setups/$SETUP/volumes/cloudbeaver/workspace:/opt/cloudbeaver/workspace
      - ./setups/$SETUP/volumes/cloudbeaver/workspace:/var/cloudbeaver/workspace
    # need to leave this unspecified here, because clients that use traefik
    # need it that way, and there's no way to remove a port through 
    # overrides yet.
    # see https://github.com/docker/compose/issues/3729
    # IMPORTANT: might need to turn this on for a client.
    # ports:
    #   - 8978:8978
    restart: unless-stopped
    networks:
      - ladder99
    logging:
      options:
        max-size: '20m'

  # ---------------------------------------------------------------------------
  # dozzle
  # ---------------------------------------------------------------------------
  # ui for docker logs
  dozzle:
    container_name: dozzle
    image: amir20/dozzle:latest
    profiles:
      - dozzle
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - /etc/timezone:/etc/timezone:ro
      - /var/run/docker.sock:/var/run/docker.sock
    ports:
      - 8080:8080
    restart: unless-stopped
    networks:
      - ladder99
    logging:
      options:
        max-size: '20m'

  # ---------------------------------------------------------------------------
  # grafana
  # ---------------------------------------------------------------------------
  # show real-time data from the database, handle notifications
  #. can't upgrade beyond 8.3.5 yet - get Origin not allowed error on dash - how fix?
  # see https://github.com/grafana/grafana/issues/45117
  # see https://grafana.com/tutorials/run-grafana-behind-a-proxy/#configure-traefik
  # see https://goteleport.com/docs/application-access/getting-started/
  grafana:
    container_name: grafana
    image: grafana/grafana:8.2.2
    # image: grafana/grafana-oss:9.1.0
    profiles:
      - grafana
    ports:
      - '$GRAFANA_PORT:3000/tcp'
    environment:
      # need these for provisioning datasource.
      # null is a docker convention for passing values in through envars -
      PGHOST: null
      PGPORT: null
      PGDATABASE: null
      PGUSER: null
      PGPASSWORD: null
      # grafana will download and install these plugins automatically
      # https://grafana.com/docs/grafana/latest/installation/docker/#install-plugins-in-the-docker-container
      # can turn this off in client override yaml with an empty string "" if device won't have internet -
      # note: phlowchart takes a long time to download dependencies, so skipping for now
      # GF_INSTALL_PLUGINS: natel-discrete-panel,natel-plotly-panel,michaeldmoore-scatter-panel,dalvany-image-panel,philipsgis-phlowchart-panel
      GF_INSTALL_PLUGINS: natel-discrete-panel,natel-plotly-panel,michaeldmoore-scatter-panel,dalvany-image-panel
      # provision password - these will get used the first time grafana is run - 
      # can pass in through environment variables -
      GF_SECURITY_ADMIN_USER: null
      GF_SECURITY_ADMIN_PASSWORD: null
      # not used
      # INFLUXDB_DB:
      # INFLUXDB_USER:
      # INFLUXDB_PASSWORD:
    volumes:
      # note: grafana.ini is located in /etc/grafana by default -
      # other folders are specified there.
      - ./setups/$SETUP/volumes/grafana/etc:/etc/grafana
      - ./setups/$SETUP/volumes/grafana/var:/var/lib/grafana
      # - ./setups/common/dashboards/grafana:/etc/dashboards
      - ./volumes/grafana/dashboards:/etc/dashboards
    # as of v7.3, the Grafana Docker image runs with the root group (id 0) instead
    # of the grafana group (id 472), for better compatibility with OpenShift. [?]
    # grafana gives permission error without user:root - not on mac tho. only on arm?
    # https://community.grafana.com/t/new-docker-install-with-persistent-storage-permission-problem/10896/13
    # Speaking in generalities it is not a security problem to run a container as root. 
    # If you run as a regular user and some hacker breaks your application they will 
    # have access to whatever a regular user has access to. If you run as root and 
    # some hacker breaks your application they will have access to the entire 
    # container. It sounds like running as a regular user is safer; but in practice 
    # there is nothing important on the container that the regular user does not 
    # have access to. Hopefully the hacker does not figure out how to break out 
    # of the container. [?]
    # https://stackoverflow.com/questions/64271295/runnig-docker-as-nonroot-with-user-id-u-cant-create-var-lib#comment113675767_64272066
    user: root
    restart: unless-stopped
    networks:
      - ladder99
    logging:
      options:
        max-size: '20m'

  # ---------------------------------------------------------------------------
  # hue
  # ---------------------------------------------------------------------------
  # sql database ui
  hue:
    container_name: hue
    # https://hub.docker.com/r/gethue/hue
    # image: gethue/hue:latest
    image: gethue/hue:20220302-140101 # prefer a fixed version so doesn't keep downloading
    profiles:
      - hue
    # ports:
    #   - "8888:8888"
    dns: 8.8.8.8
    volumes:
      #. why z-hue.ini? is it an arbitrary name for hue-overrides.ini?
      # https://stackoverflow.com/questions/57116402/hue-access-to-hdfs-bypass-default-hue-ini
      - ./setups/$SETUP/volumes/hue/hue.ini:/usr/share/hue/desktop/conf/z-hue.ini
    restart: unless-stopped
    networks:
      - ladder99
    logging:
      options:
        max-size: '20m'

  # # ---------------------------------------------------------------------------
  # # logzio-logs
  # # ---------------------------------------------------------------------------
  # # monitor docker logs with logz.io
  # logzio-logs:
  #   container_name: logzio-logs
  #   image: logzio/docker-collector-logs
  #   profiles:
  #     - logzio-logs
  #   environment:
  #     LOGZIO_TOKEN: $LOGZIO_TOKEN
  #     LOGZIO_TYPE: docker_logs
  #     LOGZIO_CODEC: json
  #     skipContainerName: cloudbeaver,dozzle,hue,logzio-logs,pgadmin,portainer,traefik
  #   volumes:
  #     - /var/run/docker.sock:/var/run/docker.sock:ro
  #     - /var/run/docker/containers:/var/lib/docker/containers
  #   restart: unless-stopped
  #   networks:
  #     - ladder99
  #   logging:
  #     options:
  #       max-size: '20m'

  # ---------------------------------------------------------------------------
  # meter
  # ---------------------------------------------------------------------------
  # calculate metrics
  # note: set PGHOST, PGPORT, etc before running
  meter:
    container_name: meter
    build: ./services/meter
    profiles:
      - meter
    environment:
      # specify where code can find data.
      # can override at run time, eg to run service on windows with node.
      L99_SETUP_FOLDER: /data/setup
      # null means pass-through from environment
      PGHOST: null
      PGPORT: null
      PGDATABASE: null
      PGUSER: null
      PGPASSWORD: null
    volumes:
      - ./setups/$SETUP:/data/setup # has setup.yaml
      # - ./setups/common/schemas:/data/schemas # has schema-specific folders
    restart: unless-stopped
    networks:
      - ladder99
    logging:
      options:
        max-size: '20m'

  # ---------------------------------------------------------------------------
  # mosquitto
  # ---------------------------------------------------------------------------
  # get mqtt data from devices and publish to mtconnect adapter
  # see https://hub.docker.com/_/eclipse-mosquitto
  # and https://mosquitto.org/
  # the image defines three directories in /mosquitto - config, data, log
  mosquitto:
    container_name: mosquitto
    image: eclipse-mosquitto
    profiles:
      - mosquitto
    ports:
      - 1883:1883
    command: mosquitto -c /mosquitto/config/mosquitto.conf -v # run in verbose mode
    volumes:
      - ./setups/$SETUP/volumes/mosquitto/config:/mosquitto/config # has mosquitto.conf
      - ./setups/$SETUP/volumes/mosquitto/data:/mosquitto/data
      - ./setups/$SETUP/volumes/mosquitto/log:/mosquitto/log
    restart: unless-stopped
    networks:
      - ladder99
    # see https://kossy0701.medium.com/what-is-tty-true-in-docker-compose-yml-47a72891aee2
    tty: true
    logging:
      options:
        max-size: '20m'

  # ---------------------------------------------------------------------------
  # nodered
  # ---------------------------------------------------------------------------
  # a visual programming environment
  nodered:
    container_name: nodered
    image: nodered/node-red:2.1.6
    profiles:
      - nodered
    restart: unless-stopped
    networks:
      - ladder99
    ports:
      - '1880:1880'
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - /etc/timezone:/etc/timezone:ro
      # note: have to `sudo chown pi:pi volumes/nodered/data` manually
      # for nodered to work. if don't, nodered will keep resetting and sending
      # messages over and over, flooding the mqtt adapter.
      #. any better way?
      - ./setups/$SETUP/volumes/nodered/data:/data:rw
    logging:
      driver: 'json-file'
      options:
        max-file: '5'
        max-size: '1m'

  # ---------------------------------------------------------------------------
  # pgadmin
  # ---------------------------------------------------------------------------
  # admin console for postgres database
  #. haven't been able to get dpage/pgadmin4 to work, though it's more up-to-date
  # note: must set permissions for volumes/pgadmin directory - eg
  #   sudo chown -R 1000:50 ../setup-oxbox/volumes/pgadmin # for biarms/pgadmin4
  #   sudo chown -R 5050:5050 ../setup-oxbox/volumes/pgadmin # for dpage/pgadmin4
  # see https://www.pgadmin.org/docs/pgadmin4/development/container_deployment.html#mapped-files-and-directories
  pgadmin:
    container_name: pgadmin
    image: biarms/pgadmin4:4.21 # see https://hub.docker.com/r/biarms/pgadmin4
    # image: dpage/pgadmin4:6.11 # see https://hub.docker.com/r/dpage/pgadmin4
    profiles:
      - pgadmin
    user: root # so don't need to do chown 5050 etc?
    ports:
      - '5050:5050/tcp' # for biarms/pgadmin4
      # - '5050:80' # for dpage/pgadmin4
    volumes:
      # for biarms/pgadmin4
      - ./setups/$SETUP/volumes/pgadmin:/pgadmin
      - ./setups/$SETUP/volumes/pgadmin/config:/pgadmin/config
      # for dpage/pgadmin4
      # - ./setups/$SETUP/volumes/pgadmin:/var/lib/pgadmin
    environment:
      # for dpage/pgadmin4
      PGADMIN_DEFAULT_EMAIL: null
      PGADMIN_DEFAULT_PASSWORD: null
    restart: unless-stopped
    networks:
      - ladder99
    logging:
      options:
        max-size: '20m'

  # ---------------------------------------------------------------------------
  # play
  # ---------------------------------------------------------------------------
  # playback device recordings - uses the recorder service
  play:
    container_name: play
    build: ./services/recorder
    profiles:
      - play
    command: recorder --mode play
    volumes:
      - ./setups/$SETUP:/data/setup # has setup-specific recordings folder
      # - ./setups/common/schemas:/data/schemas # has schema-specific recordings folder
      - ./volumes/adapter/schemas:/data/schemas # has schema-specific recordings folder
    restart: unless-stopped
    networks:
      - ladder99
    logging:
      options:
        max-size: '20m'

  # ---------------------------------------------------------------------------
  # portainer
  # ---------------------------------------------------------------------------
  # docker container viewer/management
  portainer:
    container_name: portainer
    image: portainer/portainer-ce
    profiles:
      - portainer
    ports:
      - '9000:9000'
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - /etc/timezone:/etc/timezone:ro
      - /var/run/docker.sock:/var/run/docker.sock
      - ./setups/$SETUP/volumes/portainer/data:/data
    restart: unless-stopped
    networks:
      - ladder99
    logging:
      driver: 'none'

  # ---------------------------------------------------------------------------
  # postgres
  # ---------------------------------------------------------------------------
  # store structure and time-series data
  postgres:
    container_name: postgres
    # image: timescale/timescaledb:2.3.0-pg13
    image: timescale/timescaledb:2.7.0-pg13
    command: postgres -c 'max_connections=50' # need for grafana pages with lots of queries
    profiles:
      - postgres
    # need this - commented it out and relay no longer worked.
    ports:
      # - $PGPORT:5432/tcp # turn this on in setup compose-overrides.yaml if needed
      - 127.0.0.1:$PGPORT:5432/tcp # this way, only localhost can access the port
    environment:
      # the PostgreSQL image uses these environment variables.
      # re PGPASSWORD,
      #   see https://stackoverflow.com/a/6405162/243392
      #   use a .pgpass file? https://www.postgresql.org/docs/9.1/libpq-pgpass.html
      #   but PGPASSWORD's deprecation is contested -
      #   see https://stackoverflow.com/questions/6523019/postgresql-scripting-psql-execution-with-password
      POSTGRES_DB: $PGDATABASE
      POSTGRES_USERNAME: $PGUSER
      # note: POSTGRES_PASSWORD is REQUIRED.
      # the first time this is run (and the data directory is empty), it uses 
      # these envars to initialize the database. 
      # to change the db password would require an ALTER USER SQL statement, 
      # or \password in psql.
      # see https://hub.docker.com/_/postgres
      POSTGRES_PASSWORD: $PGPASSWORD
      # # note: we need PGDATA for Windows so can point to a subdirectory of the mount folder.
      # # otherwise get error saying unable to set permissions on the folder.
      # # put here so it's consistent across platforms.
      # # see https://lifesaver.codes/answer/chmod-changing-permissions-of-var-lib-postgresql-data-permission-denied-116
      # PGDATA: /var/lib/postgresql/data/pgdata
      # that didn't work. but can use wsl terminal to run ./start ?
      # see https://github.com/bitnami/bitnami-docker-postgresql/issues/237#issuecomment-672249407
      # and https://stackoverflow.com/questions/66753829/how-to-move-workspacea-simple-project-from-windows-file-system-mnt-to-linu
      # this seems to work, to use a subdir
    volumes:
      - ./setups/$SETUP/volumes/postgres/data:/var/lib/postgresql/data
      - backup:/backup # a docker volume - see backup service and end of this file
    labels:
      # see backup service for more settings
      # - 'docker-volume-backup.stop-during-backup=false'
      # note: we always write to the same filename
      - "docker-volume-backup.exec-pre=/bin/sh -c 'pg_dumpall -U $PGUSER --clean --file /backup/dumpall.sql'"
    restart: unless-stopped
    networks:
      - ladder99
    logging:
      options:
        max-size: '20m'

  # ---------------------------------------------------------------------------
  # record
  # ---------------------------------------------------------------------------
  # record device messages for future playback
  record:
    container_name: record
    build: ./services/recorder
    profiles:
      - record
    command: recorder --mode record
    environment:
      # specify where code can find data.
      # can override at run time, eg to run service on windows with node.
      L99_SETUP_FOLDER: /data/setup
      # L99_MODULES_FOLDER: /data/modules
      L99_SCHEMAS_FOLDER: /data/schemas
    volumes:
      - ./setups/$SETUP:/data/setup # has setup-specific recordings folder
      # - ./setups/common/schemas:/data/schemas # has schema-specific recordings folder
      - ./volumes/adapter/schemas:/data/schemas # has schema-specific recordings folder
    restart: unless-stopped
    networks:
      - ladder99
    logging:
      options:
        max-size: '20m'

  # ---------------------------------------------------------------------------
  # relay
  # ---------------------------------------------------------------------------
  # fetch data from agent and send to db
  relay:
    container_name: relay
    # note: must specify build OR image in setup's compose-overrides.yaml.
    # build: ./services/relay
    profiles:
      - relay
    # this runs a process manager that passes SIGTERM to your app gracefully
    # see https://maximorlov.com/process-signals-inside-docker-containers/
    init: true
    environment:
      # specify where code can find data.
      # can override at run time, eg to run service on windows with node.
      L99_SETUP_FOLDER: /data/setup
      # turn relay feedback off if needed - eg for development machine
      # null means pass-through from environment
      RELAY_FEEDBACK_OFF: null
      FETCH_INTERVAL: 2000
      FETCH_COUNT: 800
      # null means pass-through from environment
      PGHOST: null
      PGPORT: null
      PGDATABASE: null
      PGUSER: null
      PGPASSWORD: null
    # this fixes a problem on ubuntu - works on mac okay also
    #. but not on friendlywrt - host-gateway doesn't exist, or need docker>=20.10
    # see https://stackoverflow.com/a/67158212/243392
    # and https://docs.docker.com/compose/compose-file/compose-file-v3/#extra_hosts
    extra_hosts:
      - 'host.docker.internal:host-gateway'
    restart: unless-stopped
    networks:
      - ladder99
    volumes:
      - ./setups/$SETUP:/data/setup # has setup.yaml etc
    logging:
      options:
        max-size: '20m'

  # # ---------------------------------------------------------------------------
  # # sematext
  # # ---------------------------------------------------------------------------
  # # send logs to sematext.com for monitoring
  # sematext:
  #   image: sematext/agent:latest
  #   container_name: sematext
  #   profiles:
  #     - sematext
  #   environment:
  #     # - INFRA_TOKEN=$INFRA_TOKEN # set this in .env file
  #     - INFRA_TOKEN # set this in .env file
  #     - SERVER_BASE_URL=https://spm-receiver.sematext.com
  #     - LOGS_RECEIVER_URL=https://logsene-receiver.sematext.com
  #     - EVENT_RECEIVER_URL=https://event-receiver.sematext.com
  #     - COMMAND_SERVER_URL=https://command.sematext.com
  #   cap_add:
  #     - SYS_ADMIN
  #   restart: unless-stopped
  #   volumes:
  #     - /:/hostfs:ro
  #     - /etc/passwd:/etc/passwd:ro
  #     - /etc/group:/etc/group:ro
  #     - /var/run/:/var/run
  #     - /sys/kernel/debug:/sys/kernel/debug
  #     - /sys:/host/sys:ro
  #     - /dev:/hostfs/dev:ro
  #     - /var/run/docker.sock:/var/run/docker.sock:ro

  # sematext-logs:
  #   image: sematext/logagent:latest
  #   container_name: sematext-logs
  #   profiles:
  #     - sematext-logs
  #   environment:
  #     # - LOGS_TOKEN=$LOGS_TOKEN # set this in .env file
  #     - LOGS_TOKEN # set this in .env file
  #     - REGION=US
  #   cap_add:
  #     - SYS_ADMIN
  #   restart: unless-stopped
  #   volumes:
  #     - '/var/run/docker.sock:/var/run/docker.sock'

  # ---------------------------------------------------------------------------
  # simulation
  # ---------------------------------------------------------------------------
  # the built-in mtconnect agent simulation
  # cf simulator service
  simulation:
    container_name: simulation
    #. use mtconnect/agent once mtconnect publishes theirs to docker hub
    # see https://hub.docker.com/repository/docker/ladder99/agent for ours
    image: ladder99/agent:1.7.0.3-0.1.2
    # image: ladder99/agent:2.0.0.11-arm
    profiles:
      - simulation
    working_dir: /data/agent
    # note: agent will optionally print to stdout and/or dump to /data/agent/agent.log* files.
    # note: without this command, agent image runs a simulator of a cnc machine.
    # command: agent run agent.cfg
    # command: agent debug agent.cfg
    # volumes:
    #   - ./setups/$SETUP/volumes/simulation:/data/agent # should have agent.cfg, agent.xml
    ports:
      - 5001:5000
    restart: unless-stopped
    networks:
      - ladder99
    logging:
      options:
        max-size: '20m'

  # ---------------------------------------------------------------------------
  # simulator
  # ---------------------------------------------------------------------------
  # simulate a device, eg an opc-ua server
  # cf simulation service
  simulator:
    container_name: simulator
    build: ./services/simulator
    profiles:
      - simulator
    # ports:
    #   - 4334:4334
    # volumes:
    #   - ./setups/$SETUP/volumes/simulator/node:/home/node
    restart: unless-stopped
    networks:
      - ladder99
    logging:
      options:
        max-size: '20m'

  # ---------------------------------------------------------------------------
  # superset
  # ---------------------------------------------------------------------------
  # a sql-based dashboard application

  # ---------------------------------------------------------------------------
  # traefik
  # ---------------------------------------------------------------------------
  # a reverse proxy
  # will need to add labels to grafana or other service you want to expose -
  # see client-demo/compose-overrides.yaml or client-oxbox for examples.
  traefik:
    image: traefik:v2.5.3
    container_name: traefik
    profiles:
      - traefik
    ports:
      - 80:80/tcp
      - 443:443/tcp
    command:
      - --certresolv.myresolver.acme.storage=/etc/traefik/acme.json
    restart: unless-stopped
    volumes:
      # will need to do this before starting traefik -
      #   mkdir ../client-oxbox/volumes/traefik
      #   touch ../client-oxbox/volumes/traefik/acme.json
      #   chmod 600 ../client-oxbox/volumes/traefik/acme.json
      #. is that correct?
      - /var/run/docker.sock:/var/run/docker.sock
      # - ./setups/$SETUP/volumes/traefik/traefik.toml:/traefik.toml
      # - ./setups/$SETUP/volumes/traefik/traefik_dynamic.toml:/traefik_dynamic.toml
      # - ./setups/$SETUP/volumes/traefik/traefik.toml:/shared/traefik.toml
      # - ./setups/$SETUP/volumes/traefik/traefik_dynamic.toml:/shared/traefik_dynamic.toml
      # can't do this as docker-compose will create acme.json as a directory - 
      # "docker-compose only creates folders, acme.json can be a folder name, 
      # it's impossible for it to know you want it to be a file. So if that file isn't 
      # present at that path when you create the container, it will create a folder."
      # and if you try manually creating a blank file and set chmod 600 on it, 
      # traefik will complain.
      # https://williamhayes.medium.com/traefik-letsencrypt-and-acme-json-configuration-problems-5780c914351d
      # - ./setups/$SETUP/volumes/traefik/acme.json:/acme.json
      # so need to mount the directory?
      - ./setups/$SETUP/volumes/traefik/:/etc/traefik/
    networks:
      - ladder99
    logging:
      options:
        max-size: '20m'

networks:
  ladder99:
    name: ladder99

# docker volume to share data between backup and postgres services
volumes:
  backup:
